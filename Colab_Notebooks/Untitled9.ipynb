{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7YbX+RDQMaUgolh1Djg6+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XxzBidXHP9l","executionInfo":{"status":"ok","timestamp":1664989633688,"user_tz":240,"elapsed":15234,"user":{"displayName":"Gopichand Tadapaneni","userId":"03585690741399571165"}},"outputId":"4b028cdb-0a18-41d2-9bfa-038c66128ac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  13.8M      0  0:00:05  0:00:05 --:--:-- 17.1M\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","!rm -r aclImdb/train/unsup"]},{"cell_type":"code","source":["import os, pathlib, shutil, random\n","from tensorflow import keras\n","batch_size = 32\n","base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category)\n","    files = os.listdir(train_dir / category)\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:]\n","    for fname in val_files:\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname)\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size=batch_size\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pk4UuVn6HVDB","executionInfo":{"status":"ok","timestamp":1664989644646,"user_tz":240,"elapsed":7188,"user":{"displayName":"Gopichand Tadapaneni","userId":"03585690741399571165"}},"outputId":"363849b6-e746-45ae-fa88-08db3eea0a0a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(\n","    max_tokens=max_tokens,\n","    output_mode=\"int\",\n","    output_sequence_length=max_length,\n",")\n","text_vectorization.adapt(text_only_train_ds)\n","\n","int_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"],"metadata":{"id":"j-pwrcX2Hanz","executionInfo":{"status":"ok","timestamp":1664989677243,"user_tz":240,"elapsed":7381,"user":{"displayName":"Gopichand Tadapaneni","userId":"03585690741399571165"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["for inputs, targets in int_train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AsEPrU_HiiM","executionInfo":{"status":"ok","timestamp":1664989768149,"user_tz":240,"elapsed":162,"user":{"displayName":"Gopichand Tadapaneni","userId":"03585690741399571165"}},"outputId":"655d935c-04a1-488b-edb9-a32182b3aebb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32, 600)\n","inputs.dtype: <dtype: 'int64'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor(\n","[ 3028  4473  4108    13    13  1195  4027 12119  7944  7872     1  3652\n","  1748  1917     1  9254   172   599     1  3366   230  1357     1    13\n","    33  4008     1    13  4649   156    20  3028  4473     7    43     3\n","  1059   767   294    36  6282     3   635  1719     4     7  1951    33\n","     3  1108     5     2   512  5576  4558    12   487    89    78     3\n","  7797     1  1527    36    44  7504     4     1     5    32  2412  2128\n","    78    24   644    31    24   339    52    27   528   138   138    60\n","     6    28   488  3028     1    13     2   765    93  2428     7    73\n","    39     2   644 15514     5  3028  4473   300     9     7 11929 12472\n","  5971     4  6489     5     3   751     5   367  6687     1  1343   292\n","     6    96   139    12   145    26    73     8  1121    17   231   326\n","   988     2    20     7   666     3   204     5  9305   218   847    12\n","    25   238     5 14554   292    17   103     4    34  3769    65    12\n","    60   327   197     2  2105     5 19931    59 14115    13     2  1059\n","    36     7  6810     1     7   254    33  4027 12119    36   351  3028\n","  4473    14    21     3   987  6746    17    93    39  6060    24   107\n","   439  3028  4473   100    34  2773    17     2    97  1385  4803  1014\n","   767 10364    27     7   254    33  7944  7872    36    44   445  2586\n"," 11324    11   334    17     2  2254   993  5266     3     1  3222 14130\n","    13    48     7     3   716  2712     8    11    19    15    74    15\n","  7913  4817     5   137  1191  3028  8763  4776   644   519     4 14621\n","   758     9    44  4473     4 10364 13585   126     2  1564   107  4483\n","   254    33     1  3652    16   190    40   264     4    40  1871     5\n","     3  3371  6901    91    33    40   537   341    36    14   900   544\n","    33 10364  3689 11674    78   547   137     4     3   280    16   106\n","  8987     8     2    20    81     3   635   107     7     2  4473     1\n","     3   120    39 16572    12     7 16410    16  3028  4473   300     9\n","     7  5473    33     1     1    37     2  2781   221     2     1    13\n","  3028  4473     7     3    19    12    10   250   178    85    10   119\n","    10   237    22   574     3  2449   313     5     2   863    18    54\n","    56   734   334   164  3567   250     2    20     6    24     1     2\n","    19     7   374     5  4760  1568     4   570   690    10   110   250\n","   524  2846    43     2   103    48     7    57  1316   949   688    47\n","  3068   647   947   983     2    73   436  5324    20   429     1    61\n","  2893   739  2926     5     2   191  1092     7     9   101    73     6\n","   911    16    12   168   602     5   151     8    11     1     7  4895\n","   163     4   919   122  1087     2   424   371  1563     7   159    18\n","     3   945     5 11210  1752  1969     4  3386     5    29  1011  3028\n","  8763  4876     1    13     8    93    39    11     2   313     1    16\n","     1     6   329    96    46    49    69   586     4    49    69    22\n","     8  3028  4473    48    25    57   136  7191    11     7 15082   159\n","    51    71     3  1089    62    16     2   152    36 12722    66   748\n","     5   253    10   237  1491     5   154  1829   221   628     3   162\n","   148   588   488     1    61   173  4242   748     5  3938     4  1671\n","     4     2   152   423    66   253    62    17    32     2     1     4\n","  3938    18     9   101  3430   139   913    16   170    19   313     1\n","    13     3   107    12    10   250   108   309    46     3   167     7\n","  8763   578    36    33     2   129     5     2    19    10   124    44\n","    22  2272     5    49    40   392    14    55     7   333    60    15\n","     3   115     1    10   887    86    55    14   333     6  1027     2], shape=(600,), dtype=int64)\n","targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pjLN5bE_H6aT"},"execution_count":null,"outputs":[]}]}