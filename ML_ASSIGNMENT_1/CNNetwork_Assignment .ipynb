{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO0aPZfJsthR",
        "outputId": "e5934f1d-a20e-4818-8100-6819e6e08e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTIVGTtOtW2V"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/BigDA/movie_reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-EOfUTEhvCgU",
        "outputId": "2f1da038-4cff-49a1-df9d-026944533958"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9be816dc-46c1-4f39-8d80-5a1e67b32a8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9be816dc-46c1-4f39-8d80-5a1e67b32a8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9be816dc-46c1-4f39-8d80-5a1e67b32a8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9be816dc-46c1-4f39-8d80-5a1e67b32a8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CzqrBra83ocM",
        "outputId": "83cd0449-7945-48b8-b073-7f396ae433d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-76e34ec5-0569-40de-b42d-6b32f76954c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76e34ec5-0569-40de-b42d-6b32f76954c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76e34ec5-0569-40de-b42d-6b32f76954c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76e34ec5-0569-40de-b42d-6b32f76954c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['sentiment'] = [1 if sentiment == 'positive' else 0 for sentiment in dataset['sentiment'].values]\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSjx8G4930X4",
        "outputId": "cfd05b6d-e83f-4ecf-be10-4eceb336fab5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((35000,), (15000,))"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews = dataset['review'].values\n",
        "sentiments = dataset['sentiment'].values\n",
        "\n",
        "train_reviews = reviews[:35000]\n",
        "train_sentiments = sentiments[:35000]\n",
        "\n",
        "\n",
        "test_reviews = reviews[35000:]\n",
        "test_sentiments = sentiments[35000:]\n",
        "train_reviews.shape, test_reviews.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZY6qD866Fx1"
      },
      "outputs": [],
      "source": [
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import re\n",
        "import tqdm\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  [s.extract() for s in soup(['iframe', 'script'])]\n",
        "  stripped_text = soup.get_text()\n",
        "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "  return stripped_text\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  return text\n",
        "\n",
        "def pre_process_corpus(docs):\n",
        "  norm_docs = []\n",
        "  for doc in tqdm.tqdm(docs):\n",
        "    doc = strip_html_tags(doc)\n",
        "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    doc = doc.lower()\n",
        "    doc = remove_accented_chars(doc)\n",
        "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    doc = doc.strip()  \n",
        "    norm_docs.append(doc)\n",
        "  \n",
        "  return norm_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmNsEFC66hmF",
        "outputId": "32106c44-b23d-49d0-cbd3-892e56b3fc1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35000/35000 [00:15<00:00, 2263.93it/s]\n",
            "100%|██████████| 15000/15000 [00:06<00:00, 2300.35it/s]\n"
          ]
        }
      ],
      "source": [
        "train_reviews = np.array(pre_process_corpus(train_reviews))\n",
        "test_reviews = np.array(pre_process_corpus(test_reviews))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TErSpL1f7dd_",
        "outputId": "8d98197c-35c2-49cd-c8a1-2ec7b06c0381"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side',\n",
              "       'a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done',\n",
              "       'i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovethis was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanthis may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends',\n",
              "       ...,\n",
              "       'it begins on a nice note only to falter quickly and let down expectationsmac akshay kumar and sams john abraham characters are not properly built before macs boss decides to hitch him with three air hostess rest of the drama is about how mac sam and uncle mambo paresh rawal deal with situations which at times seem forcedabout the cast paresh rawal is a very talented actor i thought was wasted in the role of a moody cook akshay kumar is tolerable john abraham is very bad keeps stumbling over furniture rajpal yadav is the only saving grace in the movie the second half of the movie is funny at times but in all a dud songs are boring and a major let down if you are hoping for some wholesome entertainment and comedy',\n",
              "       'aardman does it again next to pixar aardman animation proves again and again how to do animation properlyi had a great time watching the first episode of creature comforts i thought it translated well for american audiences my only concern is that most of the audiences arent going to get the subtle humor in this showhaving been a fan of the bbc version and the short film i knew what i was in for when i sat down to watch this the animators did a great job matching up prerecorded voices to a perfect match animal look at the first episode with the goat who sounds stoned and the dogs on the street that keep calling each other dawgis this for everyone not by a long shot in fact id be happy to see the show last for a full season but like i said before audiences arent going to get it',\n",
              "       'this movie made me laugh so much it was a bloody joke to tell you the truth so unbelievable and the worst plot ever the acting as well was bad i dont how come so many popular bollywood actors and actresses took on to do this movie the script must have been somewhat of a joke the visual effects in this movie was excrutiatingly painful to watch i believe that a kindergarten kid could have done a better job of the visual effect and a monkey could have done a better job of coming up with a plotthe plot has numerous attempts at copying major hollywood movies like the terminator but it fails miserably i laughed my head off seeing this movie a total disaster in indian cinema history'],\n",
              "      dtype='<U13326')"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMG0-VNd79EX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import array \n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D, Dropout\n",
        "from keras.initializers import Constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uieoCFyzHRf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "token = Tokenizer(num_words=5000)\n",
        "token.fit_on_texts(train_reviews)\n",
        "#vocab_size = len(token.word_index)+1\n",
        "#token2 = Tokenizer()\n",
        "#token2.fit_on_texts(test_reviews)\n",
        "#vocab_size = len(token2.word_index)+1\n",
        "#vocab_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAQ4MYId_tO8"
      },
      "outputs": [],
      "source": [
        "token.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vbxon_vACRC"
      },
      "outputs": [],
      "source": [
        "encoded_train_reviews = token.texts_to_sequences(train_reviews)\n",
        "#encoded_train_reviews = np.asarray(encoded_train_reviews)\n",
        "encoded_test_reviews = token.texts_to_sequences(test_reviews)\n",
        "#encoded_test_reviews = np.asarray(encoded_test_reviews)\n",
        "encoded_test_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrfVwgXaH8cs",
        "outputId": "56c4e6cf-fe26-401a-bdc9-d8753d89fed7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35000, 100)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(token.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(encoded_train_reviews , padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(encoded_test_reviews , padding='post', maxlen=maxlen)\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open('/content/drive/My Drive/Colab Datasets/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "metadata": {
        "id": "9W4t-KhWRt2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YusYU_ZlCM1p",
        "outputId": "a55fcc59-c233-405b-c20a-85e9451c1e13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
              "         0.82779998,  0.27061999],\n",
              "       [-0.071953  ,  0.23127   ,  0.023731  , ..., -0.71894997,\n",
              "         0.86894   ,  0.19539   ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in token.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KCxuXumJGW5"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Conv1D , MaxPooling1D, Flatten, Dropout\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(Conv1D(64,5, activation = 'relu'))\n",
        "model.add(MaxPooling1D((2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LDKVbElmssY",
        "outputId": "7ef82644-7206-4c03-eea8-4f5a40be9e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 100, 100)          17679000  \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 92, 64)            41024     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 46, 64)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 46, 64)            0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 46, 64)            4160      \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 2944)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 2945      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,791,257\n",
            "Trainable params: 112,257\n",
            "Non-trainable params: 17,679,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9waI6EhUm2S4",
        "outputId": "bf9ebf1f-aadd-48ac-ad3d-7dd86827f594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "234/234 [==============================] - 58s 245ms/step - loss: 0.5817 - acc: 0.6750\n",
            "Epoch 2/5\n",
            "234/234 [==============================] - 55s 235ms/step - loss: 0.4322 - acc: 0.7991\n",
            "Epoch 3/5\n",
            "234/234 [==============================] - 56s 240ms/step - loss: 0.3908 - acc: 0.8225\n",
            "Epoch 4/5\n",
            "234/234 [==============================] - 55s 234ms/step - loss: 0.3507 - acc: 0.8436\n",
            "Epoch 5/5\n",
            "234/234 [==============================] - 55s 234ms/step - loss: 0.3215 - acc: 0.8603\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbe201b6d50>"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "model.fit(X_train,train_sentiments ,epochs=5, batch_size=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGAx5GEvnF3h",
        "outputId": "0bf15074-1724-434a-d389-6c5ea6f0c8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_sentiments is: [0 1 0 ... 0 0 0]\n",
            "yhat_probabilities is: [[7.2326660e-03]\n",
            " [9.8865253e-01]\n",
            " [8.1551075e-04]\n",
            " ...\n",
            " [8.0506653e-02]\n",
            " [3.2564348e-01]\n",
            " [5.2513003e-02]]\n",
            "predicted classes are: [[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "Accuracy: 0.842933\n",
            "Precision: 0.884054\n",
            "Recall: 0.789880\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "yhat_probs = model.predict(X_test, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "def predict_classes( X, batch_size=128, verbose=1):\n",
        "    proba = model.predict(X, batch_size=batch_size, verbose=verbose)\n",
        "    return (proba > 0.5).astype('int32')\n",
        "\n",
        "print('test_sentiments is:',test_sentiments)\n",
        "yhat_classes =predict_classes(X_test, verbose=0)\n",
        "print('yhat_probabilities is:',yhat_probs)\n",
        "print('predicted classes are:',yhat_classes)\n",
        "# reduce to 1d array\n",
        "yhat_probs = yhat_probs[:, 0]\n",
        "yhat_classes = yhat_classes[:, 0]\n",
        " \n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(test_sentiments , yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_sentiments , yhat_classes)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(test_sentiments , yhat_classes)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZJ1XmSFkKe6"
      },
      "source": [
        "**TASK 2: Develop a Face classification system for the ‘5 Celebrity Faces Dataset.**\n",
        "\n",
        "We will use the **pre-trained Keras FaceNet model** provided by Hiroki Taniai in this ipynb file. It was trained on MS-Celeb-1M dataset and expects input images to be color, to have their pixel values whitened (standardized across all three channels), and to have a square shape of 160×160 pixels.\n",
        "\n",
        "link to download:\n",
        "https://drive.google.com/drive/folders/1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u1uQhOVJtr8",
        "outputId": "da17bee9-19a0-4793-e469-30dcc61b4aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.5)\n",
            "0.1.0\n",
            "WARNING:tensorflow:5 out of the last 596 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbe2c4e7d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbe1ed1ff80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">loaded 14 examples for class: ben_afflek\n",
            ">loaded 17 examples for class: elton_john\n",
            ">loaded 21 examples for class: jerry_seinfeld\n",
            ">loaded 19 examples for class: madonna\n",
            ">loaded 22 examples for class: mindy_kaling\n",
            "(93, 160, 160, 3) (93,)\n",
            ">loaded 5 examples for class: ben_afflek\n",
            ">loaded 5 examples for class: elton_john\n",
            ">loaded 5 examples for class: jerry_seinfeld\n",
            ">loaded 5 examples for class: madonna\n",
            ">loaded 5 examples for class: mindy_kaling\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn\n",
        "import mtcnn\n",
        "# print version\n",
        "print(mtcnn.__version__)\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        " \n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(160, 160)):\n",
        "\t# load image from file\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, if needed\n",
        "\timage = image.convert('RGB')\n",
        "\t# convert to array\n",
        "\tpixels = asarray(image)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        " \n",
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory):\n",
        "\tfaces = list()\n",
        "\t# enumerate files\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + filename\n",
        "\t\t# get face\n",
        "\t\tface = extract_face(path)\n",
        "\t\t# store\n",
        "\t\tfaces.append(face)\n",
        "\treturn faces\n",
        " \n",
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "def load_dataset(directory):\n",
        "\tX, y = list(), list()\n",
        "\t# enumerate folders, on per class\n",
        "\tfor subdir in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + subdir + '/'\n",
        "\t\t# skip any files that might be in the dir\n",
        "\t\tif not isdir(path):\n",
        "\t\t\tcontinue\n",
        "\t\t# load all faces in the subdirectory\n",
        "\t\tfaces = load_faces(path)\n",
        "\t\t# create labels\n",
        "\t\tlabels = [subdir for _ in range(len(faces))]\n",
        "\t\t# summarize progress\n",
        "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
        "\t\t# store\n",
        "\t\tX.extend(faces)\n",
        "\t\ty.extend(labels)\n",
        "\treturn asarray(X), asarray(y)\n",
        " \n",
        "# load train dataset\n",
        "trainX, trainy = load_dataset('/content/drive/MyDrive/BigDA/face_recog_dataset/train/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# load test dataset\n",
        "testX, testy = load_dataset('/content/drive/MyDrive/BigDA/face_recog_dataset/val/')\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12rP1wkEQyn7",
        "outputId": "b8fa7852-9df4-468f-93c4-59324b4df85b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded:  (93, 160, 160, 3) (93,) (25, 160, 160, 3) (25,)\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Loaded Model\n",
            "(93, 128)\n",
            "(25, 128)\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "# load the model\n",
        "#model = load_model('facenet_keras.h5')\n",
        "# summarize input and output shape\n",
        "#print(model.inputs)\n",
        "#print(model.outputs)\n",
        "\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model\n",
        " \n",
        "# get the face embedding for one face\n",
        "def get_embedding(model, face_pixels):\n",
        "\t# scale pixel values\n",
        "\tface_pixels = face_pixels.astype('float32')\n",
        "\t# standardize pixel values across channels (global)\n",
        "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
        "\tface_pixels = (face_pixels - mean) / std\n",
        "\t# transform face into one sample\n",
        "\tsamples = expand_dims(face_pixels, axis=0)\n",
        "\t# make prediction to get embedding\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat[0]\n",
        " \n",
        "# load the face dataset\n",
        "data = load('5-celebrity-faces-dataset.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "# load the facenet model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/BigDA/keras-facenet-model/keras-facenet/model/facenet_keras.h5')\n",
        "print('Loaded Model')\n",
        "# convert each face in the train set to an embedding\n",
        "newTrainX = list()\n",
        "for face_pixels in trainX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTrainX.append(embedding)\n",
        "newTrainX = asarray(newTrainX)\n",
        "print(newTrainX.shape)\n",
        "# convert each face in the test set to an embedding\n",
        "newTestX = list()\n",
        "for face_pixels in testX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTestX.append(embedding)\n",
        "newTestX = asarray(newTestX)\n",
        "print(newTestX.shape)\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('5-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TtLoFJsgxOA"
      },
      "source": [
        "**Performing Face Classification**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsMGNoeCg5IE",
        "outputId": "d600e904-0946-4d74-accf-4ea8476b952f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: train=93, test=25\n",
            "Accuracy: train=100.000, test=100.000\n"
          ]
        }
      ],
      "source": [
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "# load dataset\n",
        "data = load('5-celebrity-faces-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
        "# normalize input vectors\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# fit model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# predict\n",
        "yhat_train = model.predict(trainX)\n",
        "yhat_test = model.predict(testX)\n",
        "# score\n",
        "score_train = accuracy_score(trainy, yhat_train)\n",
        "score_test = accuracy_score(testy, yhat_test)\n",
        "# summarize\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPVKTlNdg6dW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CNN_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}